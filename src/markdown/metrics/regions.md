At CME Group, I managed a critical failover when our Central GCP region experienced a major outage, affecting our real-time risk management system. We had already configured GCP’s Global Load Balancer with automatic failover and active health checks, so within minutes, traffic was rerouted to the Eastern region. I tracked the failover process in Google Cloud Console, aiming for a failover time under 15 minutes. We successfully rerouted in under 20 minutes, meeting our SLA requirements, but encountered a 15-minute database replication lag in our Cassandra cluster between the Central and Eastern regions.

To resolve the lag, I worked with the data team and used Google Stackdriver to measure and manually sync the missing data from Google Cloud Storage backups and a third-party market data feed. This reduced the sync time from 15 minutes to 7 minutes. After the incident, I presented the metrics to the team, highlighting our 20-minute failover and 7-minute data sync while recommending improvements to our Cassandra replication strategy, which later reduced replication lag by 30%, ensuring smoother future failovers.

Manager: “So what led you to focus on the replication lag and data sync metrics?”

You: “It’s like transferring water from one container to another. You want to ensure the backup container is filled quickly, but you also need to check if it’s leaking while doing so. The replication lag was like spotting the leak—it showed us there was an issue with the consistency of the data. Once we caught that, we were able to plug the hole and fill the backup region correctly.”
